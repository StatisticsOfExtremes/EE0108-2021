library("glmnet")
install.packages("glmnet")
knitr::opts_chunk$set(echo = TRUE)
dados <- read.csv("house_data_exer_tnkc_wobasement.csv")
dados <- read.csv("house_data_exer_tnkc_wobasement.csv")
head(dados)
head(dados)
View(dados)
library(plyr)
?rename
colnames(dados)
dados %>%
rename(ï..price = price)
library(dplyr)
dados %>%
rename(ï..price = price)
dados %>%
rename(price = ï..price)
View(dados)
dados %>%
rename(price = ï..price)
View(dados)
dados %>%
rename(price = "ï..price")
names(dados)[1] <- "price"
library("glmnet")
library("tidyr")
library("dplyr")
library("plyr")
library("glmnet")
library("tidyr")
library("dplyr")
library("plyr")
library(glmnet)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE)
library(glmnet)
library(dplyr)
library(glmnet)
library(dplyr)
library(dplyr)
library(dplyr)
library(dplyr)
library(dplyr)
library(glmnet)
library(dplyr)
library(glmnet)
library(dplyr)
library(glmnet)
library(dplyr)
## separamos os dados entre treino e teste para evitar overfitting
index <- sample(nrow(dados),nrow(dados)*0.80)
dados.train <- dados[index,]
dados.test <- dados[-index,]
index_y <- which(colnames(dados)=="price")
#Como o pacote `gmlnet` não aceita dataframes, precisamos converter
#os dados para matrix
X.train <- as.matrix(dados.train[,-index_y])
Y.train <- as.matrix(dados.train[,index_y])
X.test <- as.matrix(dados.test[,-index_y])
Y.test <- as.matrix(dados.test[,index_y])
ridge.fit <- glmnet(x= X.train, y=Y.train, family="gaussian", alpha=0)
plot(ridge.fit, xvar="Lambda", label=TRUE)
ridge.fit <- glmnet(x= X.train, y=Y.train, family="gaussian", alpha=0)
plot(ridge.fit, xvar="lambda", label=TRUE)
cv.ridge <-  cv.glmnet(x=X.train, y=Y.train, family="gaussian", alpha=0, nfolds=10)
plot(cv.ridge)
coef(cv.ridge, s=cv.ridge$lambda.min)
Y_pred.ridge <- predict(ridge.fit, newx = X.test, s=cv.ridge$lambda.min)
MSE_ridge=mean((Y.test-Y_pred.lasso)^2)
ridge.fit <- glmnet(x= X.train, y=Y.train, family="gaussian", alpha=0)
plot(ridge.fit, xvar="lambda", label=TRUE)
cv.ridge <-  cv.glmnet(x=X.train, y=Y.train, family="gaussian", alpha=0, nfolds=10)
plot(cv.ridge)
coef(cv.ridge, s=cv.ridge$lambda.min)
Y_pred.ridge <- predict(ridge.fit, newx = X.test, s=cv.ridge$lambda.min)
MSE_ridge=mean((Y.test-Y_pred.ridge)^2)
knitr::opts_chunk$set(echo = TRUE)
library(broom)
library(brooom)
install.packages("broom")
library(brooom)
library(broom)
estimadorElasticNet <- function(x_treino, y_treino, x_teste, y_teste, alpha, folds = 10) {
elastic.fit <- glmnet(x=X.train, y=Y.train,family="gaussian",alpha=alpha)
cv.elastic <- cv.glmnet(x=X.train, y=Y.train, family="gaussian", alpha=alpha, nfolds=folds)
coef(cv.elastic, s= cv.elastic$lambda.min)
}
estimadorElasticNet(x_treino = X.train, y_treino = Y.train, x_teste = X.test, y_teste = Y.test, alpha = 0.5)
estimadorElasticNet <- function(x_treino, y_treino, x_teste, y_teste, alpha, folds = 10) {
elastic.fit <- gmlnet::glmnet(x=X.train, y=Y.train,family="gaussian",alpha=alpha)
cv.elastic <- glmnet::cv.glmnet(x=X.train, y=Y.train, family="gaussian", alpha=alpha, nfolds=folds)
coef(cv.elastic, s= cv.elastic$lambda.min)
}
estimadorElasticNet(x_treino = X.train, y_treino = Y.train, x_teste = X.test, y_teste = Y.test, alpha = 0.5)
estimadorElasticNet <- function(x_treino, y_treino, x_teste, y_teste, alpha, folds = 10) {
elastic.fit <- glmnet::glmnet(x=X.train, y=Y.train,family="gaussian",alpha=alpha)
cv.elastic <- glmnet::cv.glmnet(x=X.train, y=Y.train, family="gaussian", alpha=alpha, nfolds=folds)
coef(cv.elastic, s= cv.elastic$lambda.min)
}
estimadorElasticNet(x_treino = X.train, y_treino = Y.train, x_teste = X.test, y_teste = Y.test, alpha = 0.5)
install.packages("Rcpp")
install.packages("Rcpp")
knitr::opts_chunk$set(echo = TRUE)
estimadorElasticNet <- function(x_treino, y_treino, x_teste, y_teste, alpha, folds = 10) {
elastic.fit <- glmnet::glmnet(x=X.train, y=Y.train,family="gaussian",alpha=alpha)
cv.elastic <- glmnet::cv.glmnet(x=X.train, y=Y.train, family="gaussian", alpha=alpha, nfolds=folds)
coef(cv.elastic, s= cv.elastic$lambda.min)
}
estimadorElasticNet(x_treino = X.train, y_treino = Y.train, x_teste = X.test, y_teste = Y.test, alpha = 0.5)
coefElastic <- coef(cv.elastic, s= cv.elastic$lambda.min)
#Treina o modelo
MQO.fit <- lm(Y.train~X.train)
dados <- read.csv("house_data_exer_tnkc_wobasement.csv")
head(dados)
library(glmnet)
library(dplyr)
library(broom)
library(tibble)
library(purrr)
library(magrittr)
dados <- read.csv("house_data_exer_tnkc_wobasement.csv")
head(dados)
names(dados)[1] <- "price"
set.seed(123)
## separamos os dados entre treino e teste para evitar overfitting
index <- sample(nrow(dados),nrow(dados)*0.80)
dados.train <- dados[index,]
dados.test <- dados[-index,]
index_y <- which(colnames(dados)=="price")
#Como o pacote `gmlnet` não aceita dataframes, precisamos converter
#os dados para matrix
X.train <- as.matrix(dados.train[,-index_y])
Y.train <- as.matrix(dados.train[,index_y])
X.test <- as.matrix(dados.test[,-index_y])
Y.test <- as.matrix(dados.test[,index_y])
#Treina o modelo
MQO.fit <- lm(Y.train~X.train)
MQO.fit.coef <-  as.matrix(MQO.fit$coefficients)
#É adicionado 1 na primeira coluna para multiplicar pelo \beta_{0}
X.test_1 <- cbind(1,X.test)
#Preve o modelo no dataset de teste
Y_pred.MQO <- X.test_1 %*% MQO.fit.coef
MSE_MQO <- mean((Y.test-Y_pred.MQO)^2)
#treinamos o modelo com o dataset de treino
ridge.fit <- glmnet(x = X.train, y = Y.train, family = "gaussian", alpha = 0)
plot(ridge.fit, xvar="lambda", label=TRUE)
cv.ridge <-  cv.glmnet(x=X.train, y=Y.train, family="gaussian", alpha=0, nfolds=10)
plot(cv.ridge)
coef(cv.ridge, s=cv.ridge$lambda.min)
Y_pred.ridge <- predict(ridge.fit, newx = X.test, s=cv.ridge$lambda.min)
MSE_ridge=mean((Y.test-Y_pred.ridge)^2)
lasso.fit <- glmnet(x=X.train, y=Y.train, family="gaussian", alpha=1)
plot(lasso.fit,xvar="lambda", label=TRUE)
cv.lasso <- cv.glmnet(x=X.train, y=Y.train,family="gaussian", alpha=1, nfolds=10)
plot(cv.lasso)
coef(cv.lasso, s=cv.lasso$lambda.min)
Y_pred.lasso <- predict(lasso.fit, newx = X.test, s=cv.lasso$lambda.min)
MSE_lasso <- mean((Y.test-Y_pred.lasso)^2)
EQM <- cbind("EQM" = c(MSE_MQO, MSE_ridge, MSE_lasso))
rownames(EQM) <- c("MQO", "Ridge", "LASSO")
EQM
estimadorElasticNet <- function(x_treino, y_treino, x_teste, y_teste, alpha, folds = 10) {
elastic.fit <- glmnet::glmnet(x=X.train, y=Y.train,family="gaussian",alpha=alpha)
cv.elastic <- glmnet::cv.glmnet(x = X.train, y = Y.train, family = "gaussian", alpha = alpha, nfolds=folds)
coefElastic <- broom::tidy(coef(cv.elastic, s = cv.elastic$lambda.min))
Y_pred.elastic <- predict(elastic.fit, newx = X.test, s = cv.elastic$lambda.min)
MSE_elastic <- mean(( Y.test-Y_pred.elastic)^2 )
elasticTibble <- tibble::tibble(
coeficientes = list(coefElastic),
cv = list(cv.elastic),
MSE = MSE_elastic
)
}
alphas <- c(.25, .5, .75)
elasticAlphas <- purrr::map_df(alphas,  ~estimadorElasticNet(x_treino = X.train, y_treino = Y.train, x_teste = X.test, y_teste = Y.test, alpha = .x) %>% cbind(alpha = .x))
MSE_elastic <- elasticAlphas %>% select(MSE, alpha)
MSE_elastic %>% knitr::kable(., format="html")
EQMTotal <- cbind("EQM" = c(MSE_MQO, MSE_ridge, MSE_lasso, MSE_elastic$MSE))
rownames(EQMTotal) <- c("MQO", "Ridge", "LASSO", "ELASTIC(0.25)", "ELASTIC(0.50)", "ELASTIC(0.75)")
print(EQMTotal)
unlink("Relatório_cache", recursive = TRUE)
View(EQM)
set.seed(123)
## separamos os dados entre treino e teste para evitar overfitting
index <- sample(nrow(dados),nrow(dados)*0.80)
dados.train <- dados[index,]
dados.test <- dados[-index,]
index_y <- which(colnames(dados)=="price")
#Como o pacote `gmlnet` não aceita dataframes, precisamos converter
#os dados para matrix
X.train <- as.matrix(dados.train[,-index_y])
Y.train <- as.matrix(dados.train[,index_y])
X.test <- as.matrix(dados.test[,-index_y])
Y.test <- as.matrix(dados.test[,index_y])
#Treina o modelo
MQO.fit <- lm(Y.train~X.train)
MQO.fit.coef <-  as.matrix(MQO.fit$coefficients)
#É adicionado 1 na primeira coluna para multiplicar pelo \beta_{0}
X.test_1 <- cbind(1,X.test)
#Preve o modelo no dataset de teste
Y_pred.MQO <- X.test_1 %*% MQO.fit.coef
MSE_MQO <- mean((Y.test-Y_pred.MQO)^2)
View(EQM)
cv.ridge <-  cv.glmnet(x=X.train, y=Y.train, family="gaussian", alpha=0, nfolds=10)
plot(cv.ridge)
coef(cv.ridge, s=cv.ridge$lambda.min)
Y_pred.ridge <- predict(ridge.fit, newx = X.test, s=cv.ridge$lambda.min)
MSE_ridge=mean((Y.test-Y_pred.ridge)^2)
MSE_ridge <- mean((Y.test-Y_pred.ridge)^2)
MSE_ridge <- mean((Y.test-Y_pred.ridge)^2)
dados <- read.csv("house_data_exer_tnkc_wobasement.csv")
head(dados)
names(dados)[1] <- "price"
set.seed(1234)
set.seed(1234)
## separamos os dados entre treino e teste para evitar overfitting
index <- sample(nrow(dados),nrow(dados)*0.80)
dados.train <- dados[index,]
dados.test <- dados[-index,]
index_y <- which(colnames(dados)=="price")
#Como o pacote `gmlnet` não aceita dataframes, precisamos converter
#os dados para matrix
X.train <- as.matrix(dados.train[,-index_y])
Y.train <- as.matrix(dados.train[,index_y])
X.test <- as.matrix(dados.test[,-index_y])
Y.test <- as.matrix(dados.test[,index_y])
#Treina o modelo
MQO.fit <- lm(Y.train~X.train)
MQO.fit.coef <-  as.matrix(MQO.fit$coefficients)
#É adicionado 1 na primeira coluna para multiplicar pelo \beta_{0}
X.test_1 <- cbind(1,X.test)
#Preve o modelo no dataset de teste
Y_pred.MQO <- X.test_1 %*% MQO.fit.coef
MSE_MQO <- mean((Y.test-Y_pred.MQO)^2)
#treinamos o modelo com o dataset de treino
ridge.fit <- glmnet(x = X.train, y = Y.train, family = "gaussian", alpha = 0)
plot(ridge.fit, xvar="lambda", label=TRUE)
cv.ridge <-  cv.glmnet(x=X.train, y=Y.train, family="gaussian", alpha=0, nfolds=10)
plot(cv.ridge)
coef(cv.ridge, s=cv.ridge$lambda.min)
Y_pred.ridge <- predict(ridge.fit, newx = X.test, s=cv.ridge$lambda.min)
MSE_ridge <- mean((Y.test-Y_pred.ridge)^2)
lasso.fit <- glmnet(x=X.train, y=Y.train, family="gaussian", alpha=1)
plot(lasso.fit,xvar="lambda", label=TRUE)
cv.lasso <- cv.glmnet(x=X.train, y=Y.train,family="gaussian", alpha=1, nfolds=10)
plot(cv.lasso)
coef(cv.lasso, s=cv.lasso$lambda.min)
Y_pred.lasso <- predict(lasso.fit, newx = X.test, s=cv.lasso$lambda.min)
MSE_lasso <- mean((Y.test-Y_pred.lasso)^2)
EQM <- cbind("EQM" = c(MSE_MQO, MSE_ridge, MSE_lasso))
rownames(EQM) <- c("MQO", "Ridge", "LASSO")
EQM
estimadorElasticNet <- function(x_treino, y_treino, x_teste, y_teste, alpha, folds = 10) {
elastic.fit <- glmnet::glmnet(x=X.train, y=Y.train,family="gaussian",alpha=alpha)
cv.elastic <- glmnet::cv.glmnet(x = X.train, y = Y.train, family = "gaussian", alpha = alpha, nfolds=folds)
coefElastic <- broom::tidy(coef(cv.elastic, s = cv.elastic$lambda.min))
Y_pred.elastic <- predict(elastic.fit, newx = X.test, s = cv.elastic$lambda.min)
MSE_elastic <- mean(( Y.test-Y_pred.elastic)^2 )
elasticTibble <- tibble::tibble(
coeficientes = list(coefElastic),
cv = list(cv.elastic),
MSE = MSE_elastic
)
}
alphas <- c(.25, .5, .75)
elasticAlphas <- purrr::map_df(alphas,  ~estimadorElasticNet(x_treino = X.train, y_treino = Y.train, x_teste = X.test, y_teste = Y.test, alpha = .x) %>% cbind(alpha = .x))
MSE_elastic <- elasticAlphas %>% select(MSE, alpha)
MSE_elastic %>% knitr::kable(., format="html")
EQMTotal <- cbind("EQM" = c(MSE_MQO, MSE_ridge, MSE_lasso, MSE_elastic$MSE))
rownames(EQMTotal) <- c("MQO", "Ridge", "LASSO", "ELASTIC(0.25)", "ELASTIC(0.50)", "ELASTIC(0.75)")
print(EQMTotal)
set.seed(123)
set.seed(123)
## separamos os dados entre treino e teste para evitar overfitting
index <- sample(nrow(dados),nrow(dados)*0.80)
dados.train <- dados[index,]
dados.test <- dados[-index,]
index_y <- which(colnames(dados)=="price")
#Como o pacote `gmlnet` não aceita dataframes, precisamos converter
#os dados para matrix
X.train <- as.matrix(dados.train[,-index_y])
Y.train <- as.matrix(dados.train[,index_y])
X.test <- as.matrix(dados.test[,-index_y])
Y.test <- as.matrix(dados.test[,index_y])
#Treina o modelo
MQO.fit <- lm(Y.train~X.train)
MQO.fit.coef <-  as.matrix(MQO.fit$coefficients)
#É adicionado 1 na primeira coluna para multiplicar pelo \beta_{0}
X.test_1 <- cbind(1,X.test)
#Preve o modelo no dataset de teste
Y_pred.MQO <- X.test_1 %*% MQO.fit.coef
MSE_MQO <- mean((Y.test-Y_pred.MQO)^2)
#treinamos o modelo com o dataset de treino
ridge.fit <- glmnet(x = X.train, y = Y.train, family = "gaussian", alpha = 0)
plot(ridge.fit, xvar="lambda", label=TRUE)
cv.ridge <-  cv.glmnet(x=X.train, y=Y.train, family="gaussian", alpha=0, nfolds=10)
plot(cv.ridge)
coef(cv.ridge, s=cv.ridge$lambda.min)
Y_pred.ridge <- predict(ridge.fit, newx = X.test, s=cv.ridge$lambda.min)
MSE_ridge <- mean((Y.test-Y_pred.ridge)^2)
lasso.fit <- glmnet(x=X.train, y=Y.train, family="gaussian", alpha=1)
plot(lasso.fit,xvar="lambda", label=TRUE)
cv.lasso <- cv.glmnet(x=X.train, y=Y.train,family="gaussian", alpha=1, nfolds=10)
plot(cv.lasso)
coef(cv.lasso, s=cv.lasso$lambda.min)
Y_pred.lasso <- predict(lasso.fit, newx = X.test, s=cv.lasso$lambda.min)
MSE_lasso <- mean((Y.test-Y_pred.lasso)^2)
EQM <- cbind("EQM" = c(MSE_MQO, MSE_ridge, MSE_lasso))
rownames(EQM) <- c("MQO", "Ridge", "LASSO")
EQM
estimadorElasticNet <- function(x_treino, y_treino, x_teste, y_teste, alpha, folds = 10) {
elastic.fit <- glmnet::glmnet(x=X.train, y=Y.train,family="gaussian",alpha=alpha)
cv.elastic <- glmnet::cv.glmnet(x = X.train, y = Y.train, family = "gaussian", alpha = alpha, nfolds=folds)
coefElastic <- broom::tidy(coef(cv.elastic, s = cv.elastic$lambda.min))
Y_pred.elastic <- predict(elastic.fit, newx = X.test, s = cv.elastic$lambda.min)
MSE_elastic <- mean(( Y.test-Y_pred.elastic)^2 )
elasticTibble <- tibble::tibble(
coeficientes = list(coefElastic),
cv = list(cv.elastic),
MSE = MSE_elastic
)
}
alphas <- c(.25, .5, .75)
elasticAlphas <- purrr::map_df(alphas,  ~estimadorElasticNet(x_treino = X.train, y_treino = Y.train, x_teste = X.test, y_teste = Y.test, alpha = .x) %>% cbind(alpha = .x))
MSE_elastic <- elasticAlphas %>% select(MSE, alpha)
MSE_elastic %>% knitr::kable(., format="html")
EQMTotal <- cbind("EQM" = c(MSE_MQO, MSE_ridge, MSE_lasso, MSE_elastic$MSE))
rownames(EQMTotal) <- c("MQO", "Ridge", "LASSO", "ELASTIC(0.25)", "ELASTIC(0.50)", "ELASTIC(0.75)")
print(EQMTotal)
set.seed(123)
## separamos os dados entre treino e teste para evitar overfitting
index <- sample(nrow(dados),nrow(dados)*0.80)
dados.train <- dados[index,]
dados.test <- dados[-index,]
index_y <- which(colnames(dados)=="price")
#Como o pacote `gmlnet` não aceita dataframes, precisamos converter
#os dados para matrix
X.train <- as.matrix(dados.train[,-index_y])
Y.train <- as.matrix(dados.train[,index_y])
X.test <- as.matrix(dados.test[,-index_y])
Y.test <- as.matrix(dados.test[,index_y])
#Treina o modelo
MQO.fit <- lm(Y.train~X.train)
MQO.fit.coef <-  as.matrix(MQO.fit$coefficients)
#É adicionado 1 na primeira coluna para multiplicar pelo \beta_{0}
X.test_1 <- cbind(1,X.test)
#Preve o modelo no dataset de teste
Y_pred.MQO <- X.test_1 %*% MQO.fit.coef
MSE_MQO <- mean((Y.test-Y_pred.MQO)^2)
library("glmnet")
library("dplyr")
library("broom")
library("tibble")
library("purrr")
library("magrittr")
dados <- read.csv("house_data_exer_tnkc_wobasement.csv")
head(dados)
names(dados)[1] <- "price"
set.seed(123)
## separamos os dados entre treino e teste para evitar overfitting
index <- sample(nrow(dados),nrow(dados)*0.80)
dados.train <- dados[index,]
dados.test <- dados[-index,]
index_y <- which(colnames(dados)=="price")
#Como o pacote `gmlnet` não aceita dataframes, precisamos converter
#os dados para matrix
X.train <- as.matrix(dados.train[,-index_y])
Y.train <- as.matrix(dados.train[,index_y])
X.test <- as.matrix(dados.test[,-index_y])
Y.test <- as.matrix(dados.test[,index_y])
#Treina o modelo
MQO.fit <- lm(Y.train~X.train)
MQO.fit.coef <-  as.matrix(MQO.fit$coefficients)
#É adicionado 1 na primeira coluna para multiplicar pelo \beta_{0}
X.test_1 <- cbind(1,X.test)
#Preve o modelo no dataset de teste
Y_pred.MQO <- X.test_1 %*% MQO.fit.coef
MSE_MQO <- mean((Y.test-Y_pred.MQO)^2)
set.seed(13)
## separamos os dados entre treino e teste para evitar overfitting
index <- sample(nrow(dados),nrow(dados)*0.80)
dados.train <- dados[index,]
dados.test <- dados[-index,]
index_y <- which(colnames(dados)=="price")
#Como o pacote `gmlnet` não aceita dataframes, precisamos converter
#os dados para matrix
X.train <- as.matrix(dados.train[,-index_y])
Y.train <- as.matrix(dados.train[,index_y])
X.test <- as.matrix(dados.test[,-index_y])
Y.test <- as.matrix(dados.test[,index_y])
#Treina o modelo
MQO.fit <- lm(Y.train~X.train)
MQO.fit.coef <-  as.matrix(MQO.fit$coefficients)
#É adicionado 1 na primeira coluna para multiplicar pelo \beta_{0}
X.test_1 <- cbind(1,X.test)
#Preve o modelo no dataset de teste
Y_pred.MQO <- X.test_1 %*% MQO.fit.coef
MSE_MQO <- mean((Y.test-Y_pred.MQO)^2)
set.seed(1234)
MSE_elastic <- elasticAlphas %>% select(MSE, alpha)
MSE_elastic
View(MSE_elastic)
unlink("Relatório_cache", recursive = TRUE)
library(Matrix)
gc()
dev.off()
library(glmnet)
library(car)
detach("package:car", unload = TRUE)
remove.packages("glmnet", lib="~/R/win-library/4.1")
install.packages(glmnet)
install.packages("glmnet")
install.packages("glmnet")
rm(list = ls())
library(glmnet)
library(dplyr)
library(broom)
library(tibble)
library(purrr)
library(magrittr)
library(Matrix)
dados <- read.csv("house_data_exer_tnkc_wobasement.csv")
head(dados)
names(dados)[1] <- "price"
set.seed(123)
## separamos os dados entre treino e teste para evitar overfitting
index <- sample(nrow(dados),nrow(dados)*0.80)
dados.train <- dados[index,]
dados.test <- dados[-index,]
index_y <- which(colnames(dados)=="price")
#Como o pacote `gmlnet` não aceita dataframes, precisamos converter
#os dados para matrix
X.train <- as.matrix(dados.train[,-index_y])
Y.train <- as.matrix(dados.train[,index_y])
X.test <- as.matrix(dados.test[,-index_y])
Y.test <- as.matrix(dados.test[,index_y])
#Treina o modelo
MQO.fit <- lm(Y.train~X.train)
MQO.fit.coef <-  as.matrix(MQO.fit$coefficients)
#É adicionado 1 na primeira coluna para multiplicar pelo \beta_{0}
X.test_1 <- cbind(1,X.test)
#Preve o modelo no dataset de teste
Y_pred.MQO <- X.test_1 %*% MQO.fit.coef
MSE_MQO <- mean((Y.test-Y_pred.MQO)^2)
#treinamos o modelo com o dataset de treino
ridge.fit <- glmnet(x = X.train, y = Y.train, family = "gaussian", alpha = 0)
plot(ridge.fit, xvar="lambda", label=TRUE)
cv.ridge <-  cv.glmnet(x=X.train, y=Y.train, family="gaussian", alpha=0, nfolds=10)
plot(cv.ridge)
coef(cv.ridge, s=cv.ridge$lambda.min)
Y_pred.ridge <- predict(ridge.fit, newx = X.test, s=cv.ridge$lambda.min)
MSE_ridge <- mean((Y.test-Y_pred.ridge)^2)
lasso.fit <- glmnet(x=X.train, y=Y.train, family="gaussian", alpha=1)
plot(lasso.fit,xvar="lambda", label=TRUE)
cv.lasso <- cv.glmnet(x=X.train, y=Y.train,family="gaussian", alpha=1, nfolds=10)
plot(cv.lasso)
coef(cv.lasso, s=cv.lasso$lambda.min)
Y_pred.lasso <- predict(lasso.fit, newx = X.test, s=cv.lasso$lambda.min)
MSE_lasso <- mean((Y.test-Y_pred.lasso)^2)
EQM <- cbind("EQM" = c(MSE_MQO, MSE_ridge, MSE_lasso))
rownames(EQM) <- c("MQO", "Ridge", "LASSO")
EQM
estimadorElasticNet <- function(x_treino, y_treino, x_teste, y_teste, alpha, folds = 10) {
elastic.fit <- glmnet::glmnet(x=X.train, y=Y.train,family="gaussian",alpha=alpha)
cv.elastic <- glmnet::cv.glmnet(x = X.train,
y = Y.train,
family = "gaussian",
alpha = alpha,
nfolds=folds)
coefElastic <- broom::tidy(coef(cv.elastic, s = cv.elastic$lambda.min))
Y_pred.elastic <- predict(elastic.fit, newx = X.test, s = cv.elastic$lambda.min)
MSE_elastic <- mean(( Y.test-Y_pred.elastic)^2 )
elasticTibble <- tibble::tibble(
coeficientes = list(coefElastic),
cv = list(cv.elastic),
MSE = MSE_elastic
)
}
alphas <- c(.25, .5, .75)
elasticAlphas <- purrr::map_df(alphas,  ~estimadorElasticNet(x_treino = X.train, y_treino = Y.train, x_teste = X.test, y_teste = Y.test, alpha = .x) %>% cbind(alpha = .x))
MSE_elastic <- elasticAlphas %>% select(MSE, alpha)
MSE_elastic
EQMTotal <- cbind("EQM" = c(MSE_MQO, MSE_ridge, MSE_lasso, MSE_elastic$MSE))
rownames(EQMTotal) <- c("MQO", "Ridge", "LASSO", "ELASTIC(0.25)", "ELASTIC(0.50)", "ELASTIC(0.75)")
EQMTotal
names(dados)[1] <- "price"
source("~/.active-rstudio-document", encoding = 'UTF-8')
dados <- read.csv("house_data_exer_tnkc_wobasement.csv")
names(dados)[1] <- "price"
set.seed(123)
index <- sample(nrow(dados),nrow(dados)*0.80)
dados.train <- dados[index,]
dados.test <- dados[-index,]
index_y <- which(colnames(dados)=="price")
#Como o pacote `gmlnet` não aceita dataframes, precisamos converter
#os dados para matrix
X.train <- as.matrix(dados.train[,-index_y])
Y.train <- as.matrix(dados.train[,index_y])
X.test <- as.matrix(dados.test[,-index_y])
Y.test <- as.matrix(dados.test[,index_y])
MQO.fit <- lm(Y.train~X.train)
MQO.fit.coef <-  as.matrix(MQO.fit$coefficients)
#É adicionado 1 na primeira coluna para multiplicar pelo \beta_{0}
X.test_1 <- cbind(1,X.test)
#Preve o modelo no dataset de teste
Y_pred.MQO <- X.test_1 %*% MQO.fit.coef
MSE_MQO <- mean((Y.test-Y_pred.MQO)^2)
MSE_MQO
